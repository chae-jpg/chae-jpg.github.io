<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Optuna를 이용한 하이퍼파라미터 튜닝 | CS Playground</title><meta name=keywords content="ML"><meta name=description content="졸업프로젝트 당시 사용한 라이브러리인 Optuna에 대해 소개하는 글입니다."><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/optuna/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicons/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/optuna/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="http://localhost:1313/posts/optuna/"><meta property="og:site_name" content="CS Playground"><meta property="og:title" content="Optuna를 이용한 하이퍼파라미터 튜닝"><meta property="og:description" content="졸업프로젝트 당시 사용한 라이브러리인 Optuna에 대해 소개하는 글입니다."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-19T00:00:00+00:00"><meta property="article:modified_time" content="2025-05-19T00:00:00+00:00"><meta property="article:tag" content="ML"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Optuna를 이용한 하이퍼파라미터 튜닝"><meta name=twitter:description content="졸업프로젝트 당시 사용한 라이브러리인 Optuna에 대해 소개하는 글입니다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Optuna를 이용한 하이퍼파라미터 튜닝","item":"http://localhost:1313/posts/optuna/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Optuna를 이용한 하이퍼파라미터 튜닝","name":"Optuna를 이용한 하이퍼파라미터 튜닝","description":"졸업프로젝트 당시 사용한 라이브러리인 Optuna에 대해 소개하는 글입니다.","keywords":["ML"],"articleBody":"저번 학기에 이어 이번 학기도 캡스톤디자인과창업프로젝트 과목을 수강하고 있다. 현재 우리 팀의 연구는 끝났지만, 연구 과정에서 사용한 툴 한 가지를 소개하고자 한다. 바로 Oputna이다. 우리는 이 툴을 우리가 개발한 Linciever-IO 모델의 성능을 최대한 끌어낼 수 있는 하이퍼파라미터를 찾기 위해 사용하였다.\nOptuna란? 공식 사이트 Optuna는 최적화된 하이퍼파라미터를 찾아주는 프레임워크이다. 하이퍼파라미터 튜닝을 위해서는 Scikit-Learn에서 제공하는 GridSearchCV, RandomizedSearchCV와 같은 툴을 많이 사용한다. 하지만 이런 툴들은 그 알고리즘의 태생적 한계로 인해 튜닝에 있어 아주 긴 시간이 소요된다는 문제점이 존재한다. 물론 Optuna 또한 매우 빠른 것은 아니다. 이는 하이퍼파라미터 튜닝이라는 기법 자체가 결국 모든 케이스에 대해 실행해보고 비교해야 한다는 특성을 가지고 있기 때문이다. 하지만, Optuna는 위의 두 기법들과 비교해서는 훨씬 더 빠르다. 그리고, Pytorch, TensorFlow, Keras와 같은 메이저한 딥러닝 프레임워크에서 모두 사용 가능하다는 점도 아주 큰 장점이다.\n현재 Optuna의 공식 사이트는 위 세 가지 점을 장점으로 내세우고 있다. 참고하면 좋을 듯 하다.\n사용하기 Optuna의 사용을 위해서는 먼저 설치가 필요하다. 다른 패키지들과 같이 pip로 간단하게 설치할 수 있다.\npip install optuna 다음, Optuna의 하이퍼파라미터 튜닝은 objective 함수 안에서 이루어진다. 나는 튜닝을 위해 다음과 같은 함수를 만들었다.\ndef objective(trial): # 조정 원하는 파라미터 범위 선언 depth = trial.suggest_int(\"depth\", 2, 8) latent_dim = trial.suggest_int(\"latent_dim\", 128, 512, step=64) num_latents = trial.suggest_int(\"num_latents\", 64, 256, step=32) learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2) # 기기 및 모델, 옵티마이저, 손실함수 선언 device = torch.device(\"cuda\") model = PerceiverMNIST(depth=depth, latent_dim=latent_dim, num_latents=num_latents).to(device) optimizer = optim.Adam(model.parameters(), lr=learning_rate) criterion = nn.CrossEntropyLoss() # 훈련 model.train() total_loss = 0 for images, labels in trainloader: images, labels = images.to(device), labels.to(device) optimizer.zero_grad() logits = model(images) loss = criterion(logits, labels) loss.backward() optimizer.step() total_loss += loss.item() return total_loss / len(trainloader) 나머지 부분은 일반적인 Pytorch의 훈련 loop와 동일하지만, 주목할 부분은 위의 파라미터 범위를 선언한 부분이다. 앞서 말했듯, 하이퍼파라미터 튜닝을 위해서는 결국 일일히 파라미터를 설정해서 결과를 내는 것이 필요하다. 이때 내가 파라미터를 어디서부터 어디까지 테스트할 것인지 그 범위를 설정해야 한다. 이를 위 코드의 앞부분이 설정하는 것이다.\n위 코드에서 사용된 함수는 다음과 같다. suggest_int : 정수 범위를 정한다. 조정하고자 하는 파라미터의 이름과 시작, 끝을 인자로 준다. 만약 1 단위가 아니라 64, 32와 같은 단위로 숫자가 증가하도록 하고 싶다면 step=을 주면 된다. suggest_loguniform : 연속된 숫자의 범위를 정한다. 다만 이 함수는 이후 버전에서 삭제된다고 한다. 대신 suggest_float(..., log=True)를 사용하라고 한다.\n위 코드에서는 depth, latent_dim, num_latents, learning_rate 네 개의 파라미터에 대해 튜닝을 시도하였다. 범위를 선언한 뒤 해당 범위로 모델 및 학습률을 설정하고, 훈련을 시켰다.\n이를 실제로 실행하기 위해서는 다음과 같이 study를 생성한 다음, objective 함수를 인자로 주어 optimize를 수행해야 한다.\nimport optuna study = optuna.create_study(direction=\"minimize\") study.optimize(objective, n_trials=30) 여기서 create_study()의 인자인 direction=\"minimize\"는 objective 함수가 return하는 값이 감소하는 방향으로 최적화를 진행하겠다는 것을 의미한다. 여기서 위의 함수는 loss를 return하고 있기 때문에, 당연히 감소하도록 최적화하는 것이 맞다.\n이렇게 study를 생성한 후, optimize 함수로 최적화를 수행한다. objective 함수와 n_trials를 인자로 준다. n_trials는 전체 시행 횟수를 의미한다.\n코드를 실행하면 다음과 같이 trial이 시행되며 그 때의 최적 value와 파라미터, 그리고 지금까지 가장 좋은 값이 나왔던 trial을 보여준다.\n[I 2025-03-06 07:07:39,857] Trial 0 finished with value: 0.26668225020182124 and parameters: {'depth': 7, 'latent_dim': 192, 'num_latents': 64, 'learning_rate': 0.0005968324834796224}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:09:11,290] Trial 1 finished with value: 3.8591011294227306 and parameters: {'depth': 7, 'latent_dim': 320, 'num_latents': 160, 'learning_rate': 0.005783782916666108}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:09:31,260] Trial 2 finished with value: 0.3522836375556616 and parameters: {'depth': 2, 'latent_dim': 128, 'num_latents': 128, 'learning_rate': 0.0001962797474825985}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:11:02,492] Trial 3 finished with value: 4.282872916789039 and parameters: {'depth': 7, 'latent_dim': 320, 'num_latents': 160, 'learning_rate': 0.0062681789918993406}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:12:53,767] Trial 4 finished with value: 1.0389763821782207 and parameters: {'depth': 5, 'latent_dim': 384, 'num_latents': 224, 'learning_rate': 0.0031583777405563137}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:13:21,763] Trial 5 finished with value: 0.3259865055694731 and parameters: {'depth': 3, 'latent_dim': 256, 'num_latents': 96, 'learning_rate': 0.00013326825932084483}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:13:45,325] Trial 6 finished with value: 0.3730849254169444 and parameters: {'depth': 4, 'latent_dim': 128, 'num_latents': 64, 'learning_rate': 0.0032579798046704542}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:18:05,079] Trial 7 finished with value: 8.307785088732553 and parameters: {'depth': 8, 'latent_dim': 512, 'num_latents': 256, 'learning_rate': 0.005633941542665712}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:18:39,135] Trial 8 finished with value: 0.2756429120068198 and parameters: {'depth': 8, 'latent_dim': 192, 'num_latents': 64, 'learning_rate': 0.000335277034681362}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:21:02,136] Trial 9 finished with value: 11.076749913791604 and parameters: {'depth': 8, 'latent_dim': 384, 'num_latents': 192, 'learning_rate': 0.0063976046053722925}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:22:25,992] Trial 10 finished with value: 0.2677588141255224 and parameters: {'depth': 6, 'latent_dim': 512, 'num_latents': 96, 'learning_rate': 0.0006167022115396635}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:23:49,837] Trial 11 finished with value: 0.2702346246228861 and parameters: {'depth': 6, 'latent_dim': 512, 'num_latents': 96, 'learning_rate': 0.00077167476845985}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:25:02,303] Trial 12 finished with value: 0.27797159841304014 and parameters: {'depth': 6, 'latent_dim': 448, 'num_latents': 96, 'learning_rate': 0.0008276816679701316}. Best is trial 0 with value: 0.26668225020182124. [I 2025-03-06 07:25:31,583] Trial 13 finished with value: 0.25901897840483834 and parameters: {'depth': 5, 'latent_dim': 256, 'num_latents': 64, 'learning_rate': 0.0004322355545064367}. Best is trial 13 with value: 0.25901897840483834. [I 2025-03-06 07:25:55,515] Trial 14 finished with value: 0.27312530935811463 and parameters: {'depth': 4, 'latent_dim': 192, 'num_latents': 64, 'learning_rate': 0.0016535293914112447}. Best is trial 13 with value: 0.25901897840483834. [I 2025-03-06 07:26:40,226] Trial 15 finished with value: 0.2554813757209159 and parameters: {'depth': 5, 'latent_dim': 256, 'num_latents': 128, 'learning_rate': 0.0004002663484281009}. Best is trial 15 with value: 0.2554813757209159. [I 2025-03-06 07:27:24,980] Trial 16 finished with value: 0.25565995413786186 and parameters: {'depth': 5, 'latent_dim': 256, 'num_latents': 128, 'learning_rate': 0.0003776580179276335}. Best is trial 15 with value: 0.2554813757209159. [I 2025-03-06 07:28:03,775] Trial 17 finished with value: 0.2654680540221237 and parameters: {'depth': 4, 'latent_dim': 256, 'num_latents': 128, 'learning_rate': 0.0002610171011079572}. Best is trial 15 with value: 0.2554813757209159. [I 2025-03-06 07:29:10,768] Trial 18 finished with value: 0.3302811196665647 and parameters: {'depth': 3, 'latent_dim': 384, 'num_latents': 192, 'learning_rate': 0.00010365658913629019}. Best is trial 15 with value: 0.2554813757209159. [I 2025-03-06 07:29:55,467] Trial 19 finished with value: 0.2866133468489705 and parameters: {'depth': 5, 'latent_dim': 256, 'num_latents': 128, 'learning_rate': 0.0013988263583856568}. Best is trial 15 with value: 0.2554813757209159. [I 2025-03-06 07:30:51,669] Trial 20 finished with value: 0.2745055094945119 and parameters: {'depth': 3, 'latent_dim': 320, 'num_latents': 192, 'learning_rate': 0.00020538133772138157}. Best is trial 15 with value: 0.2554813757209159. [I 2025-03-06 07:31:48,387] Trial 21 finished with value: 0.25277498057449677 and parameters: {'depth': 5, 'latent_dim': 256, 'num_latents': 160, 'learning_rate': 0.00041984666204054915}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:32:35,559] Trial 22 finished with value: 0.26705718970100983 and parameters: {'depth': 5, 'latent_dim': 192, 'num_latents': 160, 'learning_rate': 0.00041908016880449524}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:33:22,563] Trial 23 finished with value: 0.27611159145244274 and parameters: {'depth': 4, 'latent_dim': 320, 'num_latents': 128, 'learning_rate': 0.0012366012560476457}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:34:13,026] Trial 24 finished with value: 0.260062302501479 and parameters: {'depth': 6, 'latent_dim': 256, 'num_latents': 128, 'learning_rate': 0.0003121371654371933}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:35:00,120] Trial 25 finished with value: 0.2908944913239748 and parameters: {'depth': 5, 'latent_dim': 192, 'num_latents': 160, 'learning_rate': 0.00017289120110738774}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:35:48,746] Trial 26 finished with value: 0.25546947501992967 and parameters: {'depth': 4, 'latent_dim': 256, 'num_latents': 160, 'learning_rate': 0.0004696972031772631}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:36:30,426] Trial 27 finished with value: 0.266836045512449 and parameters: {'depth': 4, 'latent_dim': 128, 'num_latents': 224, 'learning_rate': 0.0005274984910314277}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:37:09,359] Trial 28 finished with value: 0.32742580597692017 and parameters: {'depth': 2, 'latent_dim': 320, 'num_latents': 160, 'learning_rate': 0.0020888611036553547}. Best is trial 21 with value: 0.25277498057449677. [I 2025-03-06 07:37:47,981] Trial 29 finished with value: 0.25377385729332086 and parameters: {'depth': 3, 'latent_dim': 192, 'num_latents': 192, 'learning_rate': 0.0006198691658685506}. Best is trial 21 with value: 0.25277498057449677. study가 종료된 후에는 최적 파라미터와 최적 value가 저장된다. study.best_params와 study.best_value로 각각 이 값을 확인할 수 있다. 따라서 위에서 얻은 최적 파라미터를 이용해 같은 모델로도 하이퍼파라미터를 조정하는 것만으로 더 좋은 결과를 얻을 수 있는 것이다.\n마무리 이 글에서는 간단히 Optuna의 objective 함수를 설정하고, 이를 사용해 study를 실행하는 것까지만 다뤘지만, 실제로 Optuna의 기능은 이 외에도 더 많다.\nOptuna를 더욱 강력하게 만들어주는 툴도 존재한다. Optuna Dashboard와 OptunaHub가 그것이다. Optuna Dashboard는 말 그대로 Optuna에서 수행한 결과를 시각화하여 확인할 수 있는 대시보드이다. 최적화 히스토리나 파라미터의 중요도와 같은 값들을 확인할 수 있다. OptunaHub는 유저들이 업로드한 feature를 자유롭게 사용할 수 있는 플랫폼이다. 유저들이 제작한 강력한 feature를 사용하여 튜닝 작업을 더욱 효과적으로 진행할 수 있다.\n이렇게 이번 글에서는 Optuna의 대한 간단한 소개와 사용법, 그리고 연관된 툴까지 알아보았다. 이후에 더욱 다양한 기능들도 사용하여 연구에 큰 도움을 얻을 수 있으면 하는 바람이다.\n","wordCount":"1372","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-05-19T00:00:00Z","dateModified":"2025-05-19T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/optuna/"},"publisher":{"@type":"Organization","name":"CS Playground","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicons/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/archives/ title=archives><span>archives</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Optuna를 이용한 하이퍼파라미터 튜닝</h1><div class=post-meta><span title='2025-05-19 00:00:00 +0000 UTC'>May 19, 2025</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>Me</span>&nbsp;|&nbsp;<span>
<a href=https://github.com/chae-jpg/chae-jpg.github.io/content/posts/optuna.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#optuna란>Optuna란?</a></li><li><a href=#사용하기>사용하기</a></li><li><a href=#마무리>마무리</a></li></ul></nav></div></details></div><div class=post-content><p>저번 학기에 이어 이번 학기도 캡스톤디자인과창업프로젝트 과목을 수강하고 있다. 현재 우리 팀의 연구는 끝났지만, 연구 과정에서 사용한 툴 한 가지를 소개하고자 한다. 바로 Oputna이다.
우리는 이 툴을 우리가 개발한 Linciever-IO 모델의 성능을 최대한 끌어낼 수 있는 하이퍼파라미터를 찾기 위해 사용하였다.</p><h2 id=optuna란>Optuna란?<a hidden class=anchor aria-hidden=true href=#optuna란>#</a></h2><p><a href=https://optuna.org/>공식 사이트</a>
Optuna는 최적화된 하이퍼파라미터를 찾아주는 프레임워크이다. 하이퍼파라미터 튜닝을 위해서는 Scikit-Learn에서 제공하는 GridSearchCV, RandomizedSearchCV와 같은 툴을 많이 사용한다. 하지만 이런 툴들은 그 알고리즘의 태생적 한계로 인해 튜닝에 있어 <strong>아주 긴 시간이 소요된다는 문제점</strong>이 존재한다.
물론 Optuna 또한 매우 빠른 것은 아니다. 이는 하이퍼파라미터 튜닝이라는 기법 자체가 결국 모든 케이스에 대해 실행해보고 비교해야 한다는 특성을 가지고 있기 때문이다. 하지만, Optuna는 위의 <strong>두 기법들과 비교해서는 훨씬 더 빠르다.</strong> 그리고, Pytorch, TensorFlow, Keras와 같은 메이저한 딥러닝 프레임워크에서 모두 사용 가능하다는 점도 아주 큰 장점이다.</p><p><img loading=lazy src=https://velog.velcdn.com/images/chae-jpg/post/2cde973f-91d1-485e-88a5-8909e387ab75/image.png>
현재 Optuna의 공식 사이트는 위 세 가지 점을 장점으로 내세우고 있다. 참고하면 좋을 듯 하다.</p><h2 id=사용하기>사용하기<a hidden class=anchor aria-hidden=true href=#사용하기>#</a></h2><p>Optuna의 사용을 위해서는 먼저 설치가 필요하다. 다른 패키지들과 같이 pip로 간단하게 설치할 수 있다.</p><pre tabindex=0><code>pip install optuna
</code></pre><p>다음, Optuna의 하이퍼파라미터 튜닝은 objective 함수 안에서 이루어진다.
나는 튜닝을 위해 다음과 같은 함수를 만들었다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>objective</span><span class=p>(</span><span class=n>trial</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 조정 원하는 파라미터 범위 선언</span>
</span></span><span class=line><span class=cl>    <span class=n>depth</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_int</span><span class=p>(</span><span class=s2>&#34;depth&#34;</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>latent_dim</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_int</span><span class=p>(</span><span class=s2>&#34;latent_dim&#34;</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=n>step</span><span class=o>=</span><span class=mi>64</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>num_latents</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_int</span><span class=p>(</span><span class=s2>&#34;num_latents&#34;</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=n>step</span><span class=o>=</span><span class=mi>32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>learning_rate</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_loguniform</span><span class=p>(</span><span class=s2>&#34;learning_rate&#34;</span><span class=p>,</span> <span class=mf>1e-4</span><span class=p>,</span> <span class=mf>1e-2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 기기 및 모델, 옵티마이저, 손실함수 선언</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>PerceiverMNIST</span><span class=p>(</span><span class=n>depth</span><span class=o>=</span><span class=n>depth</span><span class=p>,</span> <span class=n>latent_dim</span><span class=o>=</span><span class=n>latent_dim</span><span class=p>,</span> <span class=n>num_latents</span><span class=o>=</span><span class=n>num_latents</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 훈련</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>trainloader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>logits</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>trainloader</span><span class=p>)</span>
</span></span></code></pre></div><p>나머지 부분은 일반적인 Pytorch의 훈련 loop와 동일하지만, 주목할 부분은 <strong>위의 파라미터 범위를 선언한 부분</strong>이다.
앞서 말했듯, 하이퍼파라미터 튜닝을 위해서는 결국 일일히 파라미터를 설정해서 결과를 내는 것이 필요하다. 이때 내가 파라미터를 어디서부터 어디까지 테스트할 것인지 그 범위를 설정해야 한다. 이를 위 코드의 앞부분이 설정하는 것이다.</p><p>위 코드에서 사용된 함수는 다음과 같다.
<code>suggest_int</code> : 정수 범위를 정한다. 조정하고자 하는 파라미터의 이름과 시작, 끝을 인자로 준다. 만약 1 단위가 아니라 64, 32와 같은 단위로 숫자가 증가하도록 하고 싶다면 step=을 주면 된다.
<code>suggest_loguniform</code> : 연속된 숫자의 범위를 정한다. 다만 이 함수는 이후 버전에서 삭제된다고 한다. 대신 <code>suggest_float(..., log=True)</code>를 사용하라고 한다.</p><p>위 코드에서는 depth, latent_dim, num_latents, learning_rate 네 개의 파라미터에 대해 튜닝을 시도하였다. 범위를 선언한 뒤 해당 범위로 모델 및 학습률을 설정하고, 훈련을 시켰다.</p><p>이를 실제로 실행하기 위해서는 다음과 같이 study를 생성한 다음, objective 함수를 인자로 주어 optimize를 수행해야 한다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>optuna</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>study</span> <span class=o>=</span> <span class=n>optuna</span><span class=o>.</span><span class=n>create_study</span><span class=p>(</span><span class=n>direction</span><span class=o>=</span><span class=s2>&#34;minimize&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>study</span><span class=o>.</span><span class=n>optimize</span><span class=p>(</span><span class=n>objective</span><span class=p>,</span> <span class=n>n_trials</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
</span></span></code></pre></div><p>여기서 <code>create_study()</code>의 인자인 <code>direction="minimize"</code>는 objective 함수가 return하는 값이 감소하는 방향으로 최적화를 진행하겠다는 것을 의미한다. 여기서 위의 함수는 loss를 return하고 있기 때문에, 당연히 감소하도록 최적화하는 것이 맞다.</p><p>이렇게 study를 생성한 후, <code>optimize</code> 함수로 최적화를 수행한다. objective 함수와 n_trials를 인자로 준다. n_trials는 전체 시행 횟수를 의미한다.</p><p>코드를 실행하면 다음과 같이 trial이 시행되며 그 때의 최적 value와 파라미터, 그리고 지금까지 가장 좋은 값이 나왔던 trial을 보여준다.</p><pre tabindex=0><code>[I 2025-03-06 07:07:39,857] Trial 0 finished with value: 0.26668225020182124 and parameters: {&#39;depth&#39;: 7, &#39;latent_dim&#39;: 192, &#39;num_latents&#39;: 64, &#39;learning_rate&#39;: 0.0005968324834796224}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:09:11,290] Trial 1 finished with value: 3.8591011294227306 and parameters: {&#39;depth&#39;: 7, &#39;latent_dim&#39;: 320, &#39;num_latents&#39;: 160, &#39;learning_rate&#39;: 0.005783782916666108}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:09:31,260] Trial 2 finished with value: 0.3522836375556616 and parameters: {&#39;depth&#39;: 2, &#39;latent_dim&#39;: 128, &#39;num_latents&#39;: 128, &#39;learning_rate&#39;: 0.0001962797474825985}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:11:02,492] Trial 3 finished with value: 4.282872916789039 and parameters: {&#39;depth&#39;: 7, &#39;latent_dim&#39;: 320, &#39;num_latents&#39;: 160, &#39;learning_rate&#39;: 0.0062681789918993406}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:12:53,767] Trial 4 finished with value: 1.0389763821782207 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 384, &#39;num_latents&#39;: 224, &#39;learning_rate&#39;: 0.0031583777405563137}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:13:21,763] Trial 5 finished with value: 0.3259865055694731 and parameters: {&#39;depth&#39;: 3, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 96, &#39;learning_rate&#39;: 0.00013326825932084483}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:13:45,325] Trial 6 finished with value: 0.3730849254169444 and parameters: {&#39;depth&#39;: 4, &#39;latent_dim&#39;: 128, &#39;num_latents&#39;: 64, &#39;learning_rate&#39;: 0.0032579798046704542}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:18:05,079] Trial 7 finished with value: 8.307785088732553 and parameters: {&#39;depth&#39;: 8, &#39;latent_dim&#39;: 512, &#39;num_latents&#39;: 256, &#39;learning_rate&#39;: 0.005633941542665712}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:18:39,135] Trial 8 finished with value: 0.2756429120068198 and parameters: {&#39;depth&#39;: 8, &#39;latent_dim&#39;: 192, &#39;num_latents&#39;: 64, &#39;learning_rate&#39;: 0.000335277034681362}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:21:02,136] Trial 9 finished with value: 11.076749913791604 and parameters: {&#39;depth&#39;: 8, &#39;latent_dim&#39;: 384, &#39;num_latents&#39;: 192, &#39;learning_rate&#39;: 0.0063976046053722925}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:22:25,992] Trial 10 finished with value: 0.2677588141255224 and parameters: {&#39;depth&#39;: 6, &#39;latent_dim&#39;: 512, &#39;num_latents&#39;: 96, &#39;learning_rate&#39;: 0.0006167022115396635}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:23:49,837] Trial 11 finished with value: 0.2702346246228861 and parameters: {&#39;depth&#39;: 6, &#39;latent_dim&#39;: 512, &#39;num_latents&#39;: 96, &#39;learning_rate&#39;: 0.00077167476845985}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:25:02,303] Trial 12 finished with value: 0.27797159841304014 and parameters: {&#39;depth&#39;: 6, &#39;latent_dim&#39;: 448, &#39;num_latents&#39;: 96, &#39;learning_rate&#39;: 0.0008276816679701316}. Best is trial 0 with value: 0.26668225020182124.
[I 2025-03-06 07:25:31,583] Trial 13 finished with value: 0.25901897840483834 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 64, &#39;learning_rate&#39;: 0.0004322355545064367}. Best is trial 13 with value: 0.25901897840483834.
[I 2025-03-06 07:25:55,515] Trial 14 finished with value: 0.27312530935811463 and parameters: {&#39;depth&#39;: 4, &#39;latent_dim&#39;: 192, &#39;num_latents&#39;: 64, &#39;learning_rate&#39;: 0.0016535293914112447}. Best is trial 13 with value: 0.25901897840483834.
[I 2025-03-06 07:26:40,226] Trial 15 finished with value: 0.2554813757209159 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 128, &#39;learning_rate&#39;: 0.0004002663484281009}. Best is trial 15 with value: 0.2554813757209159.
[I 2025-03-06 07:27:24,980] Trial 16 finished with value: 0.25565995413786186 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 128, &#39;learning_rate&#39;: 0.0003776580179276335}. Best is trial 15 with value: 0.2554813757209159.
[I 2025-03-06 07:28:03,775] Trial 17 finished with value: 0.2654680540221237 and parameters: {&#39;depth&#39;: 4, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 128, &#39;learning_rate&#39;: 0.0002610171011079572}. Best is trial 15 with value: 0.2554813757209159.
[I 2025-03-06 07:29:10,768] Trial 18 finished with value: 0.3302811196665647 and parameters: {&#39;depth&#39;: 3, &#39;latent_dim&#39;: 384, &#39;num_latents&#39;: 192, &#39;learning_rate&#39;: 0.00010365658913629019}. Best is trial 15 with value: 0.2554813757209159.
[I 2025-03-06 07:29:55,467] Trial 19 finished with value: 0.2866133468489705 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 128, &#39;learning_rate&#39;: 0.0013988263583856568}. Best is trial 15 with value: 0.2554813757209159.
[I 2025-03-06 07:30:51,669] Trial 20 finished with value: 0.2745055094945119 and parameters: {&#39;depth&#39;: 3, &#39;latent_dim&#39;: 320, &#39;num_latents&#39;: 192, &#39;learning_rate&#39;: 0.00020538133772138157}. Best is trial 15 with value: 0.2554813757209159.
[I 2025-03-06 07:31:48,387] Trial 21 finished with value: 0.25277498057449677 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 160, &#39;learning_rate&#39;: 0.00041984666204054915}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:32:35,559] Trial 22 finished with value: 0.26705718970100983 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 192, &#39;num_latents&#39;: 160, &#39;learning_rate&#39;: 0.00041908016880449524}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:33:22,563] Trial 23 finished with value: 0.27611159145244274 and parameters: {&#39;depth&#39;: 4, &#39;latent_dim&#39;: 320, &#39;num_latents&#39;: 128, &#39;learning_rate&#39;: 0.0012366012560476457}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:34:13,026] Trial 24 finished with value: 0.260062302501479 and parameters: {&#39;depth&#39;: 6, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 128, &#39;learning_rate&#39;: 0.0003121371654371933}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:35:00,120] Trial 25 finished with value: 0.2908944913239748 and parameters: {&#39;depth&#39;: 5, &#39;latent_dim&#39;: 192, &#39;num_latents&#39;: 160, &#39;learning_rate&#39;: 0.00017289120110738774}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:35:48,746] Trial 26 finished with value: 0.25546947501992967 and parameters: {&#39;depth&#39;: 4, &#39;latent_dim&#39;: 256, &#39;num_latents&#39;: 160, &#39;learning_rate&#39;: 0.0004696972031772631}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:36:30,426] Trial 27 finished with value: 0.266836045512449 and parameters: {&#39;depth&#39;: 4, &#39;latent_dim&#39;: 128, &#39;num_latents&#39;: 224, &#39;learning_rate&#39;: 0.0005274984910314277}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:37:09,359] Trial 28 finished with value: 0.32742580597692017 and parameters: {&#39;depth&#39;: 2, &#39;latent_dim&#39;: 320, &#39;num_latents&#39;: 160, &#39;learning_rate&#39;: 0.0020888611036553547}. Best is trial 21 with value: 0.25277498057449677.
[I 2025-03-06 07:37:47,981] Trial 29 finished with value: 0.25377385729332086 and parameters: {&#39;depth&#39;: 3, &#39;latent_dim&#39;: 192, &#39;num_latents&#39;: 192, &#39;learning_rate&#39;: 0.0006198691658685506}. Best is trial 21 with value: 0.25277498057449677.
</code></pre><p>study가 종료된 후에는 최적 파라미터와 최적 value가 저장된다.
<code>study.best_params</code>와 <code>study.best_value</code>로 각각 이 값을 확인할 수 있다.
<img loading=lazy src=https://velog.velcdn.com/images/chae-jpg/post/91f752e9-8eda-4307-9846-476ac42ac954/image.png></p><p>따라서 위에서 얻은 최적 파라미터를 이용해 같은 모델로도 <strong>하이퍼파라미터를 조정하는 것</strong>만으로 더 좋은 결과를 얻을 수 있는 것이다.</p><h2 id=마무리>마무리<a hidden class=anchor aria-hidden=true href=#마무리>#</a></h2><p>이 글에서는 간단히 Optuna의 objective 함수를 설정하고, 이를 사용해 study를 실행하는 것까지만 다뤘지만, 실제로 Optuna의 기능은 이 외에도 더 많다.</p><p>Optuna를 더욱 강력하게 만들어주는 툴도 존재한다. Optuna Dashboard와 OptunaHub가 그것이다.
<img loading=lazy src=https://velog.velcdn.com/images/chae-jpg/post/ecd29aa0-4ba0-4404-96f2-46a8160719fe/image.png>
Optuna Dashboard는 말 그대로 Optuna에서 수행한 결과를 시각화하여 확인할 수 있는 대시보드이다. 최적화 히스토리나 파라미터의 중요도와 같은 값들을 확인할 수 있다.
<img loading=lazy src=https://velog.velcdn.com/images/chae-jpg/post/e37db09c-9108-4441-bc0c-767f6fb9f39e/image.png>
OptunaHub는 유저들이 업로드한 feature를 자유롭게 사용할 수 있는 플랫폼이다. 유저들이 제작한 강력한 feature를 사용하여 튜닝 작업을 더욱 효과적으로 진행할 수 있다.</p><p>이렇게 이번 글에서는 Optuna의 대한 간단한 소개와 사용법, 그리고 연관된 툴까지 알아보았다. 이후에 더욱 다양한 기능들도 사용하여 연구에 큰 도움을 얻을 수 있으면 하는 바람이다.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/ml/>ML</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/jtp_5/><span class=title>« Prev</span><br><span>점프 투 파이썬 - 파이썬 문제 풀이</span>
</a><a class=next href=http://localhost:1313/posts/bert/><span class=title>Next »</span><br><span>Bidirectional Encoder Representations from Transformers (BERT) 리뷰</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Optuna를 이용한 하이퍼파라미터 튜닝 on x" href="https://x.com/intent/tweet/?text=Optuna%eb%a5%bc%20%ec%9d%b4%ec%9a%a9%ed%95%9c%20%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%20%ed%8a%9c%eb%8b%9d&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f&amp;hashtags=ML"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Optuna를 이용한 하이퍼파라미터 튜닝 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f&amp;title=Optuna%eb%a5%bc%20%ec%9d%b4%ec%9a%a9%ed%95%9c%20%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%20%ed%8a%9c%eb%8b%9d&amp;summary=Optuna%eb%a5%bc%20%ec%9d%b4%ec%9a%a9%ed%95%9c%20%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%20%ed%8a%9c%eb%8b%9d&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Optuna를 이용한 하이퍼파라미터 튜닝 on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f&title=Optuna%eb%a5%bc%20%ec%9d%b4%ec%9a%a9%ed%95%9c%20%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%20%ed%8a%9c%eb%8b%9d"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Optuna를 이용한 하이퍼파라미터 튜닝 on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Optuna를 이용한 하이퍼파라미터 튜닝 on whatsapp" href="https://api.whatsapp.com/send?text=Optuna%eb%a5%bc%20%ec%9d%b4%ec%9a%a9%ed%95%9c%20%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%20%ed%8a%9c%eb%8b%9d%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Optuna를 이용한 하이퍼파라미터 튜닝 on telegram" href="https://telegram.me/share/url?text=Optuna%eb%a5%bc%20%ec%9d%b4%ec%9a%a9%ed%95%9c%20%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%20%ed%8a%9c%eb%8b%9d&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Optuna를 이용한 하이퍼파라미터 튜닝 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Optuna%eb%a5%bc%20%ec%9d%b4%ec%9a%a9%ed%95%9c%20%ed%95%98%ec%9d%b4%ed%8d%bc%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%20%ed%8a%9c%eb%8b%9d&u=http%3a%2f%2flocalhost%3a1313%2fposts%2foptuna%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>CS Playground</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>