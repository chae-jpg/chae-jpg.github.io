<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>FedCLIP 논문 리뷰 & 코드 실행 준비 | CS Playground</title><meta name=keywords content="ML"><meta name=description content="졸업프로젝트를 위한 스터디 논문을 소개합니다."><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/fed_clip/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/fed_clip/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="http://localhost:1313/posts/fed_clip/"><meta property="og:site_name" content="CS Playground"><meta property="og:title" content="FedCLIP 논문 리뷰 & 코드 실행 준비"><meta property="og:description" content="졸업프로젝트를 위한 스터디 논문을 소개합니다."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-26T00:00:00+00:00"><meta property="article:tag" content="ML"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="FedCLIP 논문 리뷰 & 코드 실행 준비"><meta name=twitter:description content="졸업프로젝트를 위한 스터디 논문을 소개합니다."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"FedCLIP 논문 리뷰 \u0026 코드 실행 준비","item":"http://localhost:1313/posts/fed_clip/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"FedCLIP 논문 리뷰 \u0026 코드 실행 준비","name":"FedCLIP 논문 리뷰 \u0026 코드 실행 준비","description":"졸업프로젝트를 위한 스터디 논문을 소개합니다.","keywords":["ML"],"articleBody":"저는 이번 학기 캡스톤디자인을 통해 멀티모달 환경에서의 연합학습이라는 주제로 연구를 진행하고 있습니다. 연구에 도움이 될 만한 다른 연구를 찾아보는 중, fine-tuning을 위해서 엄청난 연산이 필요한 대규모 pre-trained 모델을 제한된 리소스로 학습을 진행해야 하는 연합학습 환경에 최적화시켜 적용하는 FedCLIP 연구를 발견하게 되었습니다. 이미 학습된 좋은 모델을 사용하지 못하는 환경에 맞추어 모델을 최적화한다는 발상이 흥미로웠고, 그 코드도 모두 공개가 되어있어 직접 시연을 해볼 수 있는 상황이었기 때문에 따라서 이 주제로 글을 작성하게 되었습니다.\nCLIP이란? FedCLIP에 대해 설명하기 위해서는 먼저 CLIP에 대해 간단히 알고 넘어갈 필요가 있습니다. CLIP은 2021년 OpenAI에서 공개한 이미지-텍스트 멀티모달 모델로, 논문은 다음 링크에 공개되어 있습니다. https://arxiv.org/abs/2103.00020 CLIP은 contrastive learning을 통해 학습을 진행합니다. (이름도 그래서 Contrastive Language-Image Pre-training의 줄임말) 논문의 이미지를 가지고 왔습니다. 각각 설정한 text encoder, image encoder를 통해 텍스트와 이미지를 넘기면(논문에서는 이미지에는 resnet과 vision transformer, 텍스트에는 transformer을 사용했다고 합니다) 텍스트와 이미지를 각각 벡터로 변환해줍니다. 그리고 두 벡터 쌍의 dot product를 구하면 그림과 같이 다양한 pair가 나오게 될 텐데, 여기서 색칠이 되어있는 각 텍스트와 이미지에 대응되는 pair에 가중치를 주어 학습을 시키는 것이 CLIP의 핵심입니다. 마찬가지로 논문에서 가지고 온 수도코드입니다. 보면 두 벡터의 닷 프로덕트를 구한 뒤 대응되는 pair의 cosine similarity는 크게, 그 외는 작게 만드는 것이 학습의 핵심입니다.\nFedCLIP이란 현재 CLIP은 text-image 분야에서 SOTA 모델로 알려져 있는데요, 이 모델을 연합학습 환경에도 적용할 수 있다면 정말 좋지 않을까요? 하지만 CLIP은 어마어마하게 거대한 규모의 데이터를 통해 학습한 모델이기 때문에, 그 파라미터 수도 정말 많고, 따라서 리소스가 제한되는 연합학습 환경에서는 도입하기가 어렵다는 문제점이 있습니다. 따라서 FedCLIP은 CLIP을 연합학습 환경에 맞추어 미리 학습된 인코더는 그대로 사용하고, 대신 각 기기별로 어댑터를 학습해, 이를 통합하여 하나의 완성된 어댑터를 만드는 방식으로 이 문제를 해결하였습니다. FedCLIP의 학습은 다음 과정으로 진행됩니다.\n인코더를 통과시켜 T와 I를 얻는다. I를 어댑터에 통과시켜 I* 를 얻는다. 그리고 CLIP과 같이 같은 쌍의 cosine similarity는 가깝게, 반대는 멀게 어댑터를 학습시킨다. 얻은 어댑터를 서버로 전송한다. 어댑터의 평균을 구한 뒤 해당 어댑터를 각 기기로 전송한다. 이 과정을 반복한다. 이 때 사용하는 어댑터는 어텐션을 기반으로 한 AttAI라는 어댑터로, 하나의 완전연결층, Tahn 활성화 함수, 하나의 완전 연결층, 그리고 소프트맥스로 이루어져 있습니다. 미리 학습된 인코더를 사용하여 이미 충분히 학습된 검증된 자원을 사용하면서, 인코더를 기기마다 학습시킨 뒤 통합하고 분배하여 튜닝한다는 점이 흥미롭습니다. 어댑터라는 개념의 도입을 통해 기기에서도 CLIP을 통한 학습을 가능하게 했다니, 정말 재미있지 않나요?\n참고로 여기서는 image에 adapter를 달았지만, text에 다는 것도 가능하다고 언급되어 있습니다. 해당 방식으로는 어떤 결과가 나올지도 궁금해지는 부분입니다.\n코드 실행 준비 FedCLIP의 코드는 모두 깃헙을 통해 공개되어 있습니다. https://github.com/microsoft/PersonalizedFL/tree/main/fedclip 먼저, 파이썬 버전을 3.8.5로 맞춰줍니다. 기존에 설치되어 있는 파이썬을 삭제하고 싶지 않은 경우에는, virtualenv를 통해 가상환경을 설정하는 것이 가능합니다.\n그 다음, 요구사항을 맞춰줍니다. 다음과 같은 요구사항을 맞춰줄 필요가 있습니다.\n$ pip install ftfy regex tqdm $ pip install git+https://github.com/openai/CLIP.git $ pip install -r requirements.txt $ pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/cu111/torch_stable.html 이 때, +cu111은 cuda가 설치되어 있는 윈도우즈에서만 설치가 가능합니다.\n위 요구사항을 모두 설치한 뒤, 데이터셋을 다운로드 받습니다. 사용한 데이터셋은 PACS로, 물체 인식에 사용되는 데이터셋입니다. 4개의 sub-dataset과 7개의 class를 포함하고 있습니다.\nwget https://wjdcloud.blob.core.windows.net/dataset/PACS.zip unzip PACS.zip 리눅스 환경에서는 다음 명령어를 통해 설치하고 압축 해제가 가능합니다. 다만 윈도우즈에는 wget 명령어가 존재하지 않기 때문에, 해당 링크로 바로 접속하면 다운로드가 가능합니다.\n이후 아래의 네 명령어를 각각 수행하는 것을 통해 직접 FedCLIP을 실행해볼 수 있습니다!\npython methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 0 --iters 200 --wk_iters 1 --lr 5e-05 python methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 1 --iters 200 --wk_iters 1 --lr 5e-05 python methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 2 --iters 200 --wk_iters 1 --lr 5e-05 python methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 3 --iters 200 --wk_iters 1 --lr 5e-05 다음은 윈도우즈 환경에서 직접 FedCLIP을 실행하는 글을 가져오겠습니다!\n","wordCount":"569","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-11-26T00:00:00Z","dateModified":"2024-11-26T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/fed_clip/"},"publisher":{"@type":"Organization","name":"CS Playground","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/archives/ title=archives><span>archives</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">FedCLIP 논문 리뷰 & 코드 실행 준비</h1><div class=post-meta><span title='2024-11-26 00:00:00 +0000 UTC'>November 26, 2024</span>&nbsp;·&nbsp;<span>3 min</span>&nbsp;·&nbsp;<span>Me</span>&nbsp;|&nbsp;<span>
<a href=https://github.com/%3cpath_to_repo%3e/content/posts/fed_clip.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#clip이란>CLIP이란?</a></li><li><a href=#fedclip이란>FedCLIP이란</a></li><li><a href=#코드-실행-준비>코드 실행 준비</a></li></ul></nav></div></details></div><div class=post-content><p>저는 이번 학기 캡스톤디자인을 통해 <strong>멀티모달 환경에서의 연합학습</strong>이라는 주제로 연구를 진행하고 있습니다.
연구에 도움이 될 만한 다른 연구를 찾아보는 중, fine-tuning을 위해서 엄청난 연산이 필요한 대규모 pre-trained 모델을 제한된 리소스로 학습을 진행해야 하는 연합학습 환경에 최적화시켜 적용하는 <strong>FedCLIP</strong> 연구를 발견하게 되었습니다.
이미 학습된 좋은 모델을 사용하지 못하는 환경에 맞추어 모델을 최적화한다는 발상이 흥미로웠고, 그 코드도 모두 공개가 되어있어 직접 시연을 해볼 수 있는 상황이었기 때문에 따라서 이 주제로 글을 작성하게 되었습니다.</p><h2 id=clip이란>CLIP이란?<a hidden class=anchor aria-hidden=true href=#clip이란>#</a></h2><p>FedCLIP에 대해 설명하기 위해서는 먼저 CLIP에 대해 간단히 알고 넘어갈 필요가 있습니다.
CLIP은 2021년 OpenAI에서 공개한 이미지-텍스트 멀티모달 모델로, 논문은 다음 링크에 공개되어 있습니다.
<a href=https://arxiv.org/abs/2103.00020>https://arxiv.org/abs/2103.00020</a>
CLIP은 contrastive learning을 통해 학습을 진행합니다. (이름도 그래서 Contrastive Language-Image Pre-training의 줄임말)
<img loading=lazy src=https://velog.velcdn.com/images/chae-jpg/post/d7ea25db-12bc-4094-ae18-d00b4ad153e0/image.png>
논문의 이미지를 가지고 왔습니다.
각각 설정한 text encoder, image encoder를 통해 텍스트와 이미지를 넘기면(논문에서는 이미지에는 resnet과 vision transformer, 텍스트에는 transformer을 사용했다고 합니다) 텍스트와 이미지를 각각 벡터로 변환해줍니다. 그리고 두 벡터 쌍의 dot product를 구하면 그림과 같이 다양한 pair가 나오게 될 텐데, 여기서 색칠이 되어있는 각 텍스트와 이미지에 대응되는 pair에 가중치를 주어 학습을 시키는 것이 CLIP의 핵심입니다.
<img loading=lazy src=https://velog.velcdn.com/images/chae-jpg/post/02071d35-3916-4004-b19b-a8e0cbc018aa/image.png>
마찬가지로 논문에서 가지고 온 수도코드입니다.
보면 두 벡터의 닷 프로덕트를 구한 뒤 대응되는 pair의 cosine similarity는 크게, 그 외는 작게 만드는 것이 학습의 핵심입니다.</p><h2 id=fedclip이란>FedCLIP이란<a hidden class=anchor aria-hidden=true href=#fedclip이란>#</a></h2><p>현재 CLIP은 text-image 분야에서 SOTA 모델로 알려져 있는데요, 이 모델을 연합학습 환경에도 적용할 수 있다면 정말 좋지 않을까요?
하지만 CLIP은 어마어마하게 거대한 규모의 데이터를 통해 학습한 모델이기 때문에, 그 파라미터 수도 정말 많고, 따라서 리소스가 제한되는 연합학습 환경에서는 도입하기가 어렵다는 문제점이 있습니다.
따라서 FedCLIP은 CLIP을 연합학습 환경에 맞추어 미리 학습된 인코더는 그대로 사용하고, 대신 각 기기별로 어댑터를 학습해, 이를 통합하여 하나의 완성된 어댑터를 만드는 방식으로 이 문제를 해결하였습니다.
<img loading=lazy src=https://velog.velcdn.com/images/chae-jpg/post/4c97e090-57eb-4c50-9402-7247997376ae/image.png>
FedCLIP의 학습은 다음 과정으로 진행됩니다.</p><ol><li>인코더를 통과시켜 T와 I를 얻는다.</li><li>I를 어댑터에 통과시켜 I* 를 얻는다. 그리고 CLIP과 같이 같은 쌍의 cosine similarity는 가깝게, 반대는 멀게 어댑터를 학습시킨다.</li><li>얻은 어댑터를 서버로 전송한다.</li><li>어댑터의 평균을 구한 뒤 해당 어댑터를 각 기기로 전송한다.</li><li>이 과정을 반복한다.</li></ol><p>이 때 사용하는 어댑터는 어텐션을 기반으로 한 AttAI라는 어댑터로, 하나의 완전연결층, Tahn 활성화 함수, 하나의 완전 연결층, 그리고 소프트맥스로 이루어져 있습니다.
미리 학습된 인코더를 사용하여 이미 충분히 학습된 검증된 자원을 사용하면서, 인코더를 기기마다 학습시킨 뒤 통합하고 분배하여 튜닝한다는 점이 흥미롭습니다. 어댑터라는 개념의 도입을 통해 기기에서도 CLIP을 통한 학습을 가능하게 했다니, 정말 재미있지 않나요?</p><p>참고로 여기서는 image에 adapter를 달았지만, text에 다는 것도 가능하다고 언급되어 있습니다. 해당 방식으로는 어떤 결과가 나올지도 궁금해지는 부분입니다.</p><h2 id=코드-실행-준비>코드 실행 준비<a hidden class=anchor aria-hidden=true href=#코드-실행-준비>#</a></h2><p>FedCLIP의 코드는 모두 깃헙을 통해 공개되어 있습니다.
<a href=https://github.com/microsoft/PersonalizedFL/tree/main/fedclip>https://github.com/microsoft/PersonalizedFL/tree/main/fedclip</a>
먼저, 파이썬 버전을 3.8.5로 맞춰줍니다.
기존에 설치되어 있는 파이썬을 삭제하고 싶지 않은 경우에는, virtualenv를 통해 가상환경을 설정하는 것이 가능합니다.</p><p>그 다음, 요구사항을 맞춰줍니다.
다음과 같은 요구사항을 맞춰줄 필요가 있습니다.</p><pre tabindex=0><code>$ pip install ftfy regex tqdm
$ pip install git+https://github.com/openai/CLIP.git
$ pip install -r requirements.txt
$ pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/cu111/torch_stable.html
</code></pre><p>이 때, +cu111은 cuda가 설치되어 있는 윈도우즈에서만 설치가 가능합니다.</p><p>위 요구사항을 모두 설치한 뒤, 데이터셋을 다운로드 받습니다.
사용한 데이터셋은 PACS로, 물체 인식에 사용되는 데이터셋입니다. 4개의 sub-dataset과 7개의 class를 포함하고 있습니다.</p><pre tabindex=0><code>wget https://wjdcloud.blob.core.windows.net/dataset/PACS.zip
unzip PACS.zip
</code></pre><p>리눅스 환경에서는 다음 명령어를 통해 설치하고 압축 해제가 가능합니다.
다만 윈도우즈에는 wget 명령어가 존재하지 않기 때문에, 해당 링크로 바로 접속하면 다운로드가 가능합니다.</p><p>이후 아래의 네 명령어를 각각 수행하는 것을 통해 직접 FedCLIP을 실행해볼 수 있습니다!</p><pre tabindex=0><code>python methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 0 --iters 200 --wk_iters 1 --lr 5e-05
python methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 1 --iters 200 --wk_iters 1 --lr 5e-05
python methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 2 --iters 200 --wk_iters 1 --lr 5e-05
python methods/fed_at_clip.py --dataset pacs --mode FedAtImg --test_envs 3 --iters 200 --wk_iters 1 --lr 5e-05
</code></pre><hr><p>다음은 윈도우즈 환경에서 직접 FedCLIP을 실행하는 글을 가져오겠습니다!</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/ml/>ML</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/optuna/><span class=title>« Prev</span><br><span>Optuna를 이용한 하이퍼파라미터 튜닝</span>
</a><a class=next href=http://localhost:1313/posts/boj_16236/><span class=title>Next »</span><br><span>BOJ 16236 - 아기 상어 (C++)</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share FedCLIP 논문 리뷰 & 코드 실행 준비 on x" href="https://x.com/intent/tweet/?text=FedCLIP%20%eb%85%bc%eb%ac%b8%20%eb%a6%ac%eb%b7%b0%20%26%20%ec%bd%94%eb%93%9c%20%ec%8b%a4%ed%96%89%20%ec%a4%80%eb%b9%84&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f&amp;hashtags=ML"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share FedCLIP 논문 리뷰 & 코드 실행 준비 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f&amp;title=FedCLIP%20%eb%85%bc%eb%ac%b8%20%eb%a6%ac%eb%b7%b0%20%26%20%ec%bd%94%eb%93%9c%20%ec%8b%a4%ed%96%89%20%ec%a4%80%eb%b9%84&amp;summary=FedCLIP%20%eb%85%bc%eb%ac%b8%20%eb%a6%ac%eb%b7%b0%20%26%20%ec%bd%94%eb%93%9c%20%ec%8b%a4%ed%96%89%20%ec%a4%80%eb%b9%84&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share FedCLIP 논문 리뷰 & 코드 실행 준비 on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f&title=FedCLIP%20%eb%85%bc%eb%ac%b8%20%eb%a6%ac%eb%b7%b0%20%26%20%ec%bd%94%eb%93%9c%20%ec%8b%a4%ed%96%89%20%ec%a4%80%eb%b9%84"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share FedCLIP 논문 리뷰 & 코드 실행 준비 on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share FedCLIP 논문 리뷰 & 코드 실행 준비 on whatsapp" href="https://api.whatsapp.com/send?text=FedCLIP%20%eb%85%bc%eb%ac%b8%20%eb%a6%ac%eb%b7%b0%20%26%20%ec%bd%94%eb%93%9c%20%ec%8b%a4%ed%96%89%20%ec%a4%80%eb%b9%84%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share FedCLIP 논문 리뷰 & 코드 실행 준비 on telegram" href="https://telegram.me/share/url?text=FedCLIP%20%eb%85%bc%eb%ac%b8%20%eb%a6%ac%eb%b7%b0%20%26%20%ec%bd%94%eb%93%9c%20%ec%8b%a4%ed%96%89%20%ec%a4%80%eb%b9%84&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share FedCLIP 논문 리뷰 & 코드 실행 준비 on ycombinator" href="https://news.ycombinator.com/submitlink?t=FedCLIP%20%eb%85%bc%eb%ac%b8%20%eb%a6%ac%eb%b7%b0%20%26%20%ec%bd%94%eb%93%9c%20%ec%8b%a4%ed%96%89%20%ec%a4%80%eb%b9%84&u=http%3a%2f%2flocalhost%3a1313%2fposts%2ffed_clip%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>CS Playground</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>