<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 | CS Playground</title><meta name=keywords content="DL"><meta name=description content="아주 큰 corpus를 딱 맞는 task으로 학습하기"><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/gpt-1/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn+yY=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicons/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/gpt-1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="http://localhost:1313/posts/gpt-1/"><meta property="og:site_name" content="CS Playground"><meta property="og:title" content="Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰"><meta property="og:description" content="아주 큰 corpus를 딱 맞는 task으로 학습하기"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-09-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-09-10T00:00:00+00:00"><meta property="article:tag" content="DL"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰"><meta name=twitter:description content="아주 큰 corpus를 딱 맞는 task으로 학습하기"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰","item":"http://localhost:1313/posts/gpt-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰","name":"Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰","description":"아주 큰 corpus를 딱 맞는 task으로 학습하기","keywords":["DL"],"articleBody":" Radford, A., \u0026 Narasimhan, K. (2018). Improving Language Understanding by Generative Pre-Training.\nBOAZ에서 발제를 진행한 논문이다.\n옆 링크에서 당시 발제 자료를 확인할 수 있다. 링크\nAbstract 데이터는 많은데, 특성 태스크에 맞춰져서 라벨링된 데이터는 부족. -\u003e 성능 저하로 이어짐. 이 논문에서는, generative pre-training을 통해 라벨링되지 않은 수많은 corpus를 활용하는 방법을 제안. + 태스크에 맞춰 discriminative fine-tuning fine-tuning 과정에서는, 모델의 구조는 거의 변경하지 않으면서 input을 task에 맞추어 적절하게 변형함. Introduction 라벨링되지 않은 언어 데이터가 많은데, 만약 라벨링된 데이터를 사용한다면 많은 도움이 됨. 거기에, unsupervised된 상황에서 학습이 진행되면 성능 향상에 더 도움이 됨. ex) word embeddings But, word level 이상으로 라벨링되어 있지 않은 텍스트에서 정보를 끌어내는 것은 쉽지 않음. 어떤 목적함수를 설정해야 할 지가 불분명. 목적 task에 어떻게 해야 가장 효과적으로 지식을 전달할 수 있는지 명확하지 않음. 이 논문에서는? 비지도 pre-training + 지도 fine-tuning -\u003e 준지도학습을 진행 unlabeled data로 초기 파라미터 학습 -\u003e 특정 task에 맞춰진 labeled data로 튜닝. 약간의 수정만으로도 다양한 task를 수행 가능한 공통 표현을 생성하는 것이 목표. Related Work Semi-supervised learning for NLP 단어 또는 구 수준의 통계를 계산하는데 unlabeled 데이터를 사용하는 것에서 시작. unlabeled 코퍼스를 통해 훈련하여 word embedding을 얻어 사용하는 것이 유용함이 밝혀짐. but, 단어 수준의 정보만을 얻을 수 있음. -\u003e 구, 또는 문장 수준의 임베딩을 얻는 연구가 진행됨. 본 연구도 높은 수준의 언어 맥락을 구하는 것을 목표로 함. Unsupervised pre-training 지도 학습 목표를 바꾸는 대신 좋은 초기화 시점을 찾기 위해 시작됨. 심층 신경망의 일반화에서 효과적이라는 사실이 밝혀졌고, 여러 태스크에 적용됨. 위는 주로 CV 분야이고, NLP에서도 language modeling 목표로 사전학습 후 파인튜닝을 진행한 연구가 있지만, LSTM의 한계로 성능이 좋지는 않았음. -\u003e 이 연구에서는 Transformer 구조를 사용해 그러한 제약을 극복. 사전훈련된 language model이나 기계 번역 모델의 hidden representation을 보조 feature로 사용하여 target task에 대해 supervised learning을 진행한 사례도 존재. but, 이렇게 하면 각각의 태스크에 대해 너무 많은 새 파라미터가 요구됨. -\u003e 이 연구에서는 전이 과정에서 모델 구조의 최소한의 변경을 요구하도록 함. Auxiliary training objectives 보조 목적을 NLP 태스크에 있어 사용한 사례가 많이 존재. -\u003e POS tagging, chunking, … 이 실험에서도 보조 목적을 사용함. Framework 1. Unsupervised pre-training 큰 corpus를 모델에 학습시키는 과정.\n다음과 같은 objective function을 사용 $$L_1(u) = \\sum_ilogP(u_i|u_{i-k}, …,u_{i-1};\\theta)$$\nk라는 context window를 가질 때, $i-k$ 번째부터 바로 전 토큰를 보고 $i$번째 토큰을 맞출 확률을 계산. -\u003e 여기에 log를 씌우고 전부 합함.\n해당 확률이 높아지도록 SGD를 사용해 훈련.\n모델로 Transformer decoder를 여러 층으로 사용.\nmulti-headed self-attention -\u003e position-wise feedforward layers. 2. Supervised fine-tuning 1처럼 모델을 훈련시킨 후, task에 맞춰 파라미터를 수정함. 모든 토큰을 넣은 뒤 정답 label y가 나올 확률을 transformer block을 모두 통과했을 때 최종 state $h_l^m$과 임의 하이퍼파라미터 $W_y$의 곱의 softmax로 구함. 이 값을 최대화하는 것이 목표. $$L_2(C) = \\sum_{(x, y)}log P(y|x^1,…,x^m)$$\n여기에, 언어 모델링 (위의 $L_1$ 함수)을 보조 목표로 추가하는 것이 지도 모델의 일반화 성능 향상 수렴 속도 향상 에 도움이 된다는 사실을 찾아냄. $$L_3(C) = L_2(C) + \\lambda * L_1(C)$$\n3. Task-specific input transformations classification과 같은 task는 위의 방식으로 바로 fine-tuning이 가능하지만, 몇몇 다른 task는 정해진 input 형식 (문장 쌍, 세 문장) 이를 변형하는 것이 필요함. 모델이 이러한 input을 받아들일 수 있도록 ordered sequence로 변환. -\u003e task에 따라 불필요하게 구조를 바꾸는 것을 막아줌. Similarity 두 문장에 대해 일정한 순서가 정해져 있지 않으므로, 가능한 두 순서 모두로 input을 만들어 representation을 뽑고, 서로 더함. Question Answering and Commonsense Reasoning 질문과 답에 대해 각각 input을 만든 다음 모델을 통과시키고, 가능한 답에 대해 또 softmax를 통해 확률분포를 구함. Experiments NLI에서 RTE를 제외하고 SOTA QA \u0026 CR : 모두 SOTA Classification, Semantici Similarity : SST2, MRPC를 제외한 모든 데이터셋에서 SOTA Analysis Impact of number of layers transferred layer의 수가 증가함에 따라 정확도도 증가 -\u003e pre-training이 도움이 됨. Zero-shot Behaviors Pre-training 횟수가 증가할 수록 점점 더 좋은 성능을 보임. But, LSTM은 결과가 변동성이 심함 이를 통해 Pre-training이 언어 능력을 습득하는데 도움을 줌. Transformer 구조가 지식 전이에 더욱 적합한 구조임. Ablation Studies 보조 목적 유무 : dataset이 크면 있는 것이 유리. LSTM과의 비교 : Transformer보다 낮은 성능을 보임. Pre-training 유무 : 있을 때가 더 좋은 성능을 보임. Conclusion Transformer 구조와 긴 맥락의 data + generative pre-training \u0026 discriminative fine-tuning으로 엄청난 성능 향상을 보임. Discussion 이후 논문들에서는 모델을 키우고 + 데이터셋을 늘리는 방향으로 발전시켜 실제로도 엄청난 성능 향상을 이뤄냄. -\u003e 결국 deep learning 모델은 scale이 커지는 방향으로 발전시킬 수 밖에 없는것인가… 라는 생각이 듬. 따라서 이러한 추세를 거스를 수는 없는 것 같고, 점점 더 무거워지는 모델에 대한 optimization이 더더욱 필요하겠다…라는 생각을 했음. 보조 목적을 사용했는데, BERT 같은 경우 이러한 보조 목적을 변형하여 더 좋은 성능을 얻은 변종들이 있는 것처럼 GPT도 그런 모델들이 있는지? 다른 objective가 아닌 Language Model을 선택한 이유가 있는지? -\u003e 이건 기본적인 언어 능력을 얻기 위해서는 말을 생성하는 task를 배우는 것이 다른 task에 비해서 가장 직관적으로 말을 할 수 있게 되는 것이기 때문에, 가장 효과적이지 않았을까 생각이 듬… ","wordCount":"758","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-09-10T00:00:00Z","dateModified":"2025-09-10T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/gpt-1/"},"publisher":{"@type":"Organization","name":"CS Playground","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicons/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/archives/ title=archives><span>archives</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰</h1><div class=post-meta><span title='2025-09-10 00:00:00 +0000 UTC'>September 10, 2025</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>Me</span>&nbsp;|&nbsp;<span>
<a href=https://github.com/chae-jpg/chae-jpg.github.io/content/posts/GPT-1.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#related-work>Related Work</a><ul><li><a href=#semi-supervised-learning-for-nlp>Semi-supervised learning for NLP</a></li><li><a href=#unsupervised-pre-training>Unsupervised pre-training</a></li><li><a href=#auxiliary-training-objectives>Auxiliary training objectives</a></li></ul></li><li><a href=#framework>Framework</a><ul><li><a href=#1-unsupervised-pre-training>1. Unsupervised pre-training</a></li><li><a href=#2-supervised-fine-tuning>2. Supervised fine-tuning</a></li><li><a href=#3-task-specific-input-transformations>3. Task-specific input transformations</a></li></ul></li><li><a href=#experiments>Experiments</a></li><li><a href=#analysis>Analysis</a><ul><li><a href=#impact-of-number-of-layers-transferred>Impact of number of layers transferred</a></li><li><a href=#zero-shot-behaviors>Zero-shot Behaviors</a></li><li><a href=#ablation-studies>Ablation Studies</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#discussion>Discussion</a></li></ul></nav></div></details></div><div class=post-content><blockquote><p>Radford, A., & Narasimhan, K. (2018). <strong>Improving Language Understanding by Generative Pre-Training.</strong></p></blockquote><p>BOAZ에서 발제를 진행한 논문이다.<br>옆 링크에서 당시 발제 자료를 확인할 수 있다. <a href=https://www.canva.com/design/DAGx1ANCb4M/ic4MEhXTlf5y4nlsrt-QuA/edit>링크</a></p><h2 id=abstract>Abstract<a hidden class=anchor aria-hidden=true href=#abstract>#</a></h2><ul><li>데이터는 많은데, 특성 태스크에 맞춰져서 라벨링된 데이터는 부족. -> 성능 저하로 이어짐.</li><li>이 논문에서는, <strong>generative pre-training</strong>을 통해 라벨링되지 않은 수많은 corpus를 활용하는 방법을 제안. + 태스크에 맞춰 discriminative fine-tuning</li><li>fine-tuning 과정에서는, 모델의 구조는 거의 변경하지 않으면서 input을 task에 맞추어 적절하게 변형함.</li></ul><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><ul><li>라벨링되지 않은 언어 데이터가 많은데, 만약 라벨링된 데이터를 사용한다면 많은 도움이 됨.</li><li>거기에, unsupervised된 상황에서 학습이 진행되면 성능 향상에 더 도움이 됨. ex) word embeddings</li><li>But, word level 이상으로 라벨링되어 있지 않은 텍스트에서 정보를 끌어내는 것은 쉽지 않음.<ul><li>어떤 목적함수를 설정해야 할 지가 불분명.</li><li>목적 task에 어떻게 해야 가장 효과적으로 지식을 전달할 수 있는지 명확하지 않음.</li></ul></li><li>이 논문에서는?<ul><li>비지도 pre-training + 지도 fine-tuning -> 준지도학습을 진행<ul><li>unlabeled data로 초기 파라미터 학습 -> 특정 task에 맞춰진 labeled data로 튜닝.</li></ul></li><li>약간의 수정만으로도 다양한 task를 수행 가능한 공통 표현을 생성하는 것이 목표.</li></ul></li></ul><h2 id=related-work>Related Work<a hidden class=anchor aria-hidden=true href=#related-work>#</a></h2><h3 id=semi-supervised-learning-for-nlp>Semi-supervised learning for NLP<a hidden class=anchor aria-hidden=true href=#semi-supervised-learning-for-nlp>#</a></h3><ul><li>단어 또는 구 수준의 통계를 계산하는데 unlabeled 데이터를 사용하는 것에서 시작.</li><li>unlabeled 코퍼스를 통해 훈련하여 word embedding을 얻어 사용하는 것이 유용함이 밝혀짐.<ul><li>but, 단어 수준의 정보만을 얻을 수 있음.</li></ul></li><li>-> 구, 또는 문장 수준의 임베딩을 얻는 연구가 진행됨. 본 연구도 높은 수준의 언어 맥락을 구하는 것을 목표로 함.</li></ul><h3 id=unsupervised-pre-training>Unsupervised pre-training<a hidden class=anchor aria-hidden=true href=#unsupervised-pre-training>#</a></h3><ul><li>지도 학습 목표를 바꾸는 대신 좋은 초기화 시점을 찾기 위해 시작됨.</li><li>심층 신경망의 일반화에서 효과적이라는 사실이 밝혀졌고, 여러 태스크에 적용됨.</li><li>위는 주로 CV 분야이고, NLP에서도 language modeling 목표로 사전학습 후 파인튜닝을 진행한 연구가 있지만, LSTM의 한계로 성능이 좋지는 않았음.<ul><li>-> 이 연구에서는 Transformer 구조를 사용해 그러한 제약을 극복.</li></ul></li><li>사전훈련된 language model이나 기계 번역 모델의 hidden representation을 보조 feature로 사용하여 target task에 대해 supervised learning을 진행한 사례도 존재.<ul><li>but, 이렇게 하면 각각의 태스크에 대해 너무 많은 새 파라미터가 요구됨.</li><li>-> 이 연구에서는 전이 과정에서 모델 구조의 최소한의 변경을 요구하도록 함.</li></ul></li></ul><h3 id=auxiliary-training-objectives>Auxiliary training objectives<a hidden class=anchor aria-hidden=true href=#auxiliary-training-objectives>#</a></h3><ul><li>보조 목적을 NLP 태스크에 있어 사용한 사례가 많이 존재. -> POS tagging, chunking, &mldr;</li><li>이 실험에서도 보조 목적을 사용함.</li></ul><h2 id=framework>Framework<a hidden class=anchor aria-hidden=true href=#framework>#</a></h2><h3 id=1-unsupervised-pre-training>1. Unsupervised pre-training<a hidden class=anchor aria-hidden=true href=#1-unsupervised-pre-training>#</a></h3><ul><li><p>큰 corpus를 모델에 학습시키는 과정.</p></li><li><p>다음과 같은 objective function을 사용
$$L_1(u) = \sum_ilogP(u_i|u_{i-k}, &mldr;,u_{i-1};\theta)$$</p></li><li><p>k라는 context window를 가질 때, $i-k$ 번째부터 바로 전 토큰를 보고 $i$번째 토큰을 맞출 확률을 계산. -> 여기에 log를 씌우고 전부 합함.</p></li><li><p>해당 확률이 높아지도록 SGD를 사용해 훈련.</p></li><li><p>모델로 Transformer decoder를 여러 층으로 사용.</p></li></ul><p><img loading=lazy src=/images/gpt_1.png></p><ul><li>multi-headed self-attention -> position-wise feedforward layers.</li></ul><h3 id=2-supervised-fine-tuning>2. Supervised fine-tuning<a hidden class=anchor aria-hidden=true href=#2-supervised-fine-tuning>#</a></h3><ul><li>1처럼 모델을 훈련시킨 후, task에 맞춰 파라미터를 수정함.</li><li>모든 토큰을 넣은 뒤 정답 label y가 나올 확률을 transformer block을 모두 통과했을 때 최종 state $h_l^m$과 임의 하이퍼파라미터 $W_y$의 곱의 softmax로 구함.</li><li>이 값을 최대화하는 것이 목표.</li></ul><p>$$L_2(C) = \sum_{(x, y)}log P(y|x^1,&mldr;,x^m)$$</p><ul><li>여기에, 언어 모델링 (위의 $L_1$ 함수)을 보조 목표로 추가하는 것이<ol><li>지도 모델의 일반화 성능 향상</li><li>수렴 속도 향상</li></ol></li><li>에 도움이 된다는 사실을 찾아냄.</li></ul><p>$$L_3(C) = L_2(C) + \lambda * L_1(C)$$</p><h3 id=3-task-specific-input-transformations>3. Task-specific input transformations<a hidden class=anchor aria-hidden=true href=#3-task-specific-input-transformations>#</a></h3><p><img loading=lazy src=/images/gpt_2.png></p><ul><li>classification과 같은 task는 위의 방식으로 바로 fine-tuning이 가능하지만, 몇몇 다른 task는 정해진 input 형식 (문장 쌍, 세 문장) 이를 변형하는 것이 필요함.</li><li>모델이 이러한 input을 받아들일 수 있도록 ordered sequence로 변환. -> task에 따라 불필요하게 구조를 바꾸는 것을 막아줌.</li></ul><h4 id=similarity>Similarity<a hidden class=anchor aria-hidden=true href=#similarity>#</a></h4><ul><li>두 문장에 대해 일정한 순서가 정해져 있지 않으므로, 가능한 두 순서 모두로 input을 만들어 representation을 뽑고, 서로 더함.</li></ul><h4 id=question-answering-and-commonsense-reasoning>Question Answering and Commonsense Reasoning<a hidden class=anchor aria-hidden=true href=#question-answering-and-commonsense-reasoning>#</a></h4><ul><li>질문과 답에 대해 각각 input을 만든 다음 모델을 통과시키고, 가능한 답에 대해 또 softmax를 통해 확률분포를 구함.</li></ul><h2 id=experiments>Experiments<a hidden class=anchor aria-hidden=true href=#experiments>#</a></h2><p><img loading=lazy src=/images/gpt_3.png></p><ul><li>NLI에서 RTE를 제외하고 SOTA</li></ul><p><img loading=lazy src=/images/gpt_4.png></p><ul><li>QA & CR : 모두 SOTA</li></ul><p><img loading=lazy src=/images/gpt_5.png></p><ul><li>Classification, Semantici Similarity : SST2, MRPC를 제외한 모든 데이터셋에서 SOTA</li></ul><h2 id=analysis>Analysis<a hidden class=anchor aria-hidden=true href=#analysis>#</a></h2><h3 id=impact-of-number-of-layers-transferred>Impact of number of layers transferred<a hidden class=anchor aria-hidden=true href=#impact-of-number-of-layers-transferred>#</a></h3><ul><li>layer의 수가 증가함에 따라 정확도도 증가 -> pre-training이 도움이 됨.</li></ul><h3 id=zero-shot-behaviors>Zero-shot Behaviors<a hidden class=anchor aria-hidden=true href=#zero-shot-behaviors>#</a></h3><ul><li>Pre-training 횟수가 증가할 수록 점점 더 좋은 성능을 보임.</li><li>But, LSTM은 결과가 변동성이 심함</li><li>이를 통해<ul><li>Pre-training이 언어 능력을 습득하는데 도움을 줌.</li><li>Transformer 구조가 지식 전이에 더욱 적합한 구조임.</li></ul></li></ul><h3 id=ablation-studies>Ablation Studies<a hidden class=anchor aria-hidden=true href=#ablation-studies>#</a></h3><ul><li>보조 목적 유무 : dataset이 크면 있는 것이 유리.</li><li>LSTM과의 비교 : Transformer보다 낮은 성능을 보임.</li><li>Pre-training 유무 : 있을 때가 더 좋은 성능을 보임.</li></ul><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><ul><li>Transformer 구조와 긴 맥락의 data + generative pre-training & discriminative fine-tuning으로 엄청난 성능 향상을 보임.</li></ul><h2 id=discussion>Discussion<a hidden class=anchor aria-hidden=true href=#discussion>#</a></h2><ul><li>이후 논문들에서는 모델을 키우고 + 데이터셋을 늘리는 방향으로 발전시켜 실제로도 엄청난 성능 향상을 이뤄냄. -> 결국 deep learning 모델은 scale이 커지는 방향으로 발전시킬 수 밖에 없는것인가&mldr; 라는 생각이 듬.<ul><li>따라서 이러한 추세를 거스를 수는 없는 것 같고, 점점 더 무거워지는 모델에 대한 optimization이 더더욱 필요하겠다&mldr;라는 생각을 했음.</li></ul></li><li>보조 목적을 사용했는데, BERT 같은 경우 이러한 보조 목적을 변형하여 더 좋은 성능을 얻은 변종들이 있는 것처럼 GPT도 그런 모델들이 있는지?</li><li>다른 objective가 아닌 Language Model을 선택한 이유가 있는지? -> 이건 기본적인 언어 능력을 얻기 위해서는 말을 생성하는 task를 배우는 것이 다른 task에 비해서 가장 직관적으로 말을 할 수 있게 되는 것이기 때문에, 가장 효과적이지 않았을까 생각이 듬&mldr;</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/dl/>DL</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/boj12789/><span class=title>« Prev</span><br><span>BOJ 12789 - 도키도키 간식드리미</span>
</a><a class=next href=http://localhost:1313/posts/handson_chap2/><span class=title>Next »</span><br><span>핸즈온 머신러닝 - 2장</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 on x" href="https://x.com/intent/tweet/?text=Improving%20Language%20Understanding%20by%20Generative%20Pre-Training%20%28GPT-1%29%20%eb%a6%ac%eb%b7%b0&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f&amp;hashtags=DL"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f&amp;title=Improving%20Language%20Understanding%20by%20Generative%20Pre-Training%20%28GPT-1%29%20%eb%a6%ac%eb%b7%b0&amp;summary=Improving%20Language%20Understanding%20by%20Generative%20Pre-Training%20%28GPT-1%29%20%eb%a6%ac%eb%b7%b0&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f&title=Improving%20Language%20Understanding%20by%20Generative%20Pre-Training%20%28GPT-1%29%20%eb%a6%ac%eb%b7%b0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 on whatsapp" href="https://api.whatsapp.com/send?text=Improving%20Language%20Understanding%20by%20Generative%20Pre-Training%20%28GPT-1%29%20%eb%a6%ac%eb%b7%b0%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 on telegram" href="https://telegram.me/share/url?text=Improving%20Language%20Understanding%20by%20Generative%20Pre-Training%20%28GPT-1%29%20%eb%a6%ac%eb%b7%b0&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Improving Language Understanding by Generative Pre-Training (GPT-1) 리뷰 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Improving%20Language%20Understanding%20by%20Generative%20Pre-Training%20%28GPT-1%29%20%eb%a6%ac%eb%b7%b0&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fgpt-1%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>CS Playground</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>